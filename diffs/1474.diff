--- perf_takehome.py	2026-01-21 09:20:42
+++ solution_new.py	2026-01-21 09:20:05
@@ -1,4 +1,3 @@
-
 from collections import defaultdict
 import random
 import unittest
@@ -41,6 +40,10 @@
     def add(self, engine, slot):
         self.instrs.append({engine: [slot]})
 
+    def add_packed(self, bundle):
+        """Add a packed instruction bundle. Bundle is dict {engine: [slots]}."""
+        self.instrs.append(bundle)
+
     def alloc_scratch(self, name=None, length=1):
         addr = self.scratch_ptr
         if name is not None:
@@ -57,20 +60,6 @@
             self.const_map[val] = addr
         return self.const_map[val]
 
-    def scratch_consts_batch(self, vals):
-        """Create multiple constants in bundled operations (2 per cycle)."""
-        new_vals = [v for v in vals if v not in self.const_map]
-        ops = []
-        for val in new_vals:
-            addr = self.alloc_scratch()
-            ops.append(("const", addr, val))
-            self.const_map[val] = addr
-        # Bundle in pairs
-        for i in range(0, len(ops), 2):
-            chunk = ops[i:i+2]
-            self.instrs.append({"load": chunk})
-        return [self.const_map[v] for v in vals]
-
     def build_hash(self, val_hash_addr, tmp1, tmp2, round, i):
         slots = []
         for hi, (op1, val1, op2, op3, val3) in enumerate(HASH_STAGES):
@@ -92,53 +81,48 @@
         ]
         for v in init_vars:
             self.alloc_scratch(v, 1)
+        # OPTIMIZED: Use different temp addresses to pack parameter loads
+        # Pairs: (rounds,0), (n_nodes,1), (batch_size,2), (forest_height,3), (forest_values_p,4), (inp_indices_p,5), (inp_values_p,6)
+        tmp_addrs = [tmp1, tmp2, tmp1, tmp2, tmp1, tmp2, tmp1]  # Alternate between tmp1 and tmp2
+        for i in range(0, len(init_vars), 2):
+            if i + 1 < len(init_vars):
+                # Pack 2 const loads
+                self.add_packed({"load": [("const", tmp_addrs[i], i), ("const", tmp_addrs[i+1], i+1)]})
+                # Pack 2 memory loads
+                self.add_packed({"load": [
+                    ("load", self.scratch[init_vars[i]], tmp_addrs[i]),
+                    ("load", self.scratch[init_vars[i+1]], tmp_addrs[i+1]),
+                ]})
+            else:
+                # Odd one out - defer and combine with const 0,1,2 loads below
+                odd_idx = i
+                odd_addr = tmp_addrs[i]
+                odd_var = init_vars[i]
 
-        # Pre-create ALL needed constants in batch at start (allows bundling)
-        # Tree indices: 0-14
-        tree_indices = list(range(15))
-        # Hash constants: val1, val3 from each stage, plus mul values
-        hash_consts = []
-        for hi, (op1, val1, op2, op3, val3) in enumerate(HASH_STAGES):
-            hash_consts.extend([val1, val3])
-            if op1 == "+" and op2 == "+" and op3 == "<<":
-                mul = (1 + (1 << val3)) % (2**32)
-                hash_consts.append(mul)
-        all_consts = tree_indices + hash_consts
-        self.scratch_consts_batch(all_consts)
+        # OPTIMIZED: Pack odd parameter with const 0,1,2 loads
+        zero_const = self.alloc_scratch("zero_const")
+        one_const = self.alloc_scratch("one_const")
+        two_const = self.alloc_scratch("two_const")
+        self.const_map[0] = zero_const
+        self.const_map[1] = one_const
+        self.const_map[2] = two_const
+        # Preload tree[0] for round 0 optimization
+        tree0_scalar = self.alloc_scratch("tree0_scalar")
+        tree0_v = self.alloc_scratch("tree0_v", VLEN)
+        # Combine: const for odd param + const 0
+        self.add_packed({"load": [("const", odd_addr, odd_idx), ("const", zero_const, 0)]})
+        # Combine: load odd param + const 1
+        self.add_packed({"load": [("load", self.scratch[odd_var], odd_addr), ("const", one_const, 1)]})
+        # Combine: const 2 + tree0_scalar load
+        self.add_packed({"load": [("const", two_const, 2), ("load", tree0_scalar, self.scratch["forest_values_p"])]})
 
-        # Now individual scratch_const calls will just return cached addresses
-        init_var_consts = [self.scratch_const(i) for i in range(len(init_vars))]
-
-        zero_const = self.scratch_const(0)
-        one_const = self.scratch_const(1)
-        two_const = self.scratch_const(2)
-
         zero_v = self.alloc_scratch("zero_v", VLEN)
         one_v = self.alloc_scratch("one_v", VLEN)
         two_v = self.alloc_scratch("two_v", VLEN)
         n_nodes_v = self.alloc_scratch("n_nodes_v", VLEN)
         forest_base_v = self.alloc_scratch("forest_base_v", VLEN)
-
-        # Preload tree[0] early so we can bundle its vbroadcast
-        tree0_scalar = self.alloc_scratch("tree0_scalar")
-        tree0_v = self.alloc_scratch("tree0_v", VLEN)
-
-        # Bundle init_var loads in pairs, with tree0_scalar bundled with last odd var
-        for i in range(0, len(init_vars), 2):
-            if i + 1 < len(init_vars):
-                self.instrs.append({"load": [
-                    ("load", self.scratch[init_vars[i]], init_var_consts[i]),
-                    ("load", self.scratch[init_vars[i+1]], init_var_consts[i+1]),
-                ]})
-            else:
-                # Bundle last odd init_var with tree0_scalar load
-                self.instrs.append({"load": [
-                    ("load", self.scratch[init_vars[i]], init_var_consts[i]),
-                    ("load", tree0_scalar, self.scratch["forest_values_p"]),
-                ]})
-
-        # Bundle all 6 vbroadcasts (now that tree0 is loaded)
-        self.instrs.append({"valu": [
+        # OPTIMIZED: Pack 6 vbroadcasts into 1 cycle (tree0_v added since tree0_scalar already loaded)
+        self.add_packed({"valu": [
             ("vbroadcast", zero_v, zero_const),
             ("vbroadcast", one_v, one_const),
             ("vbroadcast", two_v, two_const),
@@ -153,12 +137,38 @@
         tree1_v = self.alloc_scratch("tree1_v", VLEN)
         tree2_v = self.alloc_scratch("tree2_v", VLEN)
         diff_1_2_v = self.alloc_scratch("diff_1_2_v", VLEN)  # tree2 - tree1
+        # OPTIMIZED: Allocate const 3-6 early so we can combine ALU ops with loads
+        three_const = self.alloc_scratch("three_const")
+        four_const = self.alloc_scratch("four_const")
+        five_const = self.alloc_scratch("five_const")
+        six_const = self.alloc_scratch("six_const")
+        self.const_map[3] = three_const
+        self.const_map[4] = four_const
+        self.const_map[5] = five_const
+        self.const_map[6] = six_const
+        # OPTIMIZED: Pack tree1/tree2 ALU with const 3,4 loads (saves 1 cycle)
+        self.add_packed({
+            "alu": [
+                ("+", tree1_scalar, self.scratch["forest_values_p"], one_const),
+                ("+", tree2_scalar, self.scratch["forest_values_p"], two_const),
+            ],
+            "load": [("const", three_const, 3), ("const", four_const, 4)],
+        })
+        # OPTIMIZED: Pack tree1/tree2 loads together
+        self.add_packed({"load": [
+            ("load", tree1_scalar, tree1_scalar),
+            ("load", tree2_scalar, tree2_scalar),
+        ]})
+        # OPTIMIZED: Pack const 5,6 loads with tree1/tree2 broadcasts
+        self.add_packed({
+            "load": [("const", five_const, 5), ("const", six_const, 6)],
+            "valu": [
+                ("vbroadcast", tree1_v, tree1_scalar),
+                ("vbroadcast", tree2_v, tree2_scalar),
+            ],
+        })
 
         # Preload tree[3..6] for round 2 optimization (idx in {3,4,5,6} after round 1)
-        three_const = self.scratch_const(3)
-        four_const = self.scratch_const(4)
-        five_const = self.scratch_const(5)
-        six_const = self.scratch_const(6)
         three_v = self.alloc_scratch("three_v", VLEN)
         tree3_scalar = self.alloc_scratch("tree3_scalar")
         tree4_scalar = self.alloc_scratch("tree4_scalar")
@@ -171,141 +181,199 @@
         diff_3_4_v = self.alloc_scratch("diff_3_4_v", VLEN)  # tree4 - tree3
         diff_5_6_v = self.alloc_scratch("diff_5_6_v", VLEN)  # tree6 - tree5
 
-        # ALU ops for tree1, tree2 addresses
-        self.instrs.append({"alu": [
-            ("+", tree1_scalar, self.scratch["forest_values_p"], one_const),
-            ("+", tree2_scalar, self.scratch["forest_values_p"], two_const),
-        ]})
-        # Bundle loads for tree1, tree2 WITH ALU for tree3-6 addresses (independent ops)
-        self.instrs.append({
-            "load": [
-                ("load", tree1_scalar, tree1_scalar),
-                ("load", tree2_scalar, tree2_scalar),
+        # OPTIMIZED: Pack diff_1_2/three_v with tree3-6 ALU ops (saves 1 cycle)
+        self.add_packed({
+            "valu": [
+                ("-", diff_1_2_v, tree2_v, tree1_v),
+                ("vbroadcast", three_v, three_const),
             ],
             "alu": [
                 ("+", tree3_scalar, self.scratch["forest_values_p"], three_const),
                 ("+", tree4_scalar, self.scratch["forest_values_p"], four_const),
                 ("+", tree5_scalar, self.scratch["forest_values_p"], five_const),
                 ("+", tree6_scalar, self.scratch["forest_values_p"], six_const),
-            ]
+            ],
         })
-        # Bundle vbroadcasts for tree1/tree2
-        self.instrs.append({"valu": [
-            ("vbroadcast", tree1_v, tree1_scalar),
-            ("vbroadcast", tree2_v, tree2_scalar),
+        # OPTIMIZED: Pack loads 2 per cycle
+        # OPTIMIZED: Overlap loads with broadcasts - load tree3,4, then load tree5,6 with broadcast tree3,4
+        self.add_packed({"load": [
+            ("load", tree3_scalar, tree3_scalar),
+            ("load", tree4_scalar, tree4_scalar),
         ]})
-        # Bundle diff with three_v vbroadcast (diff depends on tree1_v/tree2_v from previous cycle)
-        self.instrs.append({"valu": [
-            ("-", diff_1_2_v, tree2_v, tree1_v),
-            ("vbroadcast", three_v, three_const),
-        ]})
-        # Preload tree[7..14] for round 3 selection - prepare ALU ops early
-        seven_const = self.scratch_const(7)
-        seven_v = self.alloc_scratch("seven_v", VLEN)
-
-        tree7_14_scalars = []
-        tree7_14_v = []
-        alu_ops_7_14 = []
-        for i in range(7, 15):
-            scalar = self.alloc_scratch(f"tree{i}_scalar")
-            vec = self.alloc_scratch(f"tree{i}_v", VLEN)
-            tree7_14_scalars.append(scalar)
-            tree7_14_v.append(vec)
-            i_const = self.scratch_const(i)
-            alu_ops_7_14.append(("+", scalar, self.scratch["forest_values_p"], i_const))
-
-        # Bundle tree3-6 loads WITH tree7-14 ALU ops (independent operations)
-        self.instrs.append({
+        self.add_packed({
             "load": [
-                ("load", tree3_scalar, tree3_scalar),
-                ("load", tree4_scalar, tree4_scalar),
-            ],
-            "alu": alu_ops_7_14[:4]  # First 4 tree7-14 address computations
-        })
-        self.instrs.append({
-            "load": [
                 ("load", tree5_scalar, tree5_scalar),
                 ("load", tree6_scalar, tree6_scalar),
             ],
-            "alu": alu_ops_7_14[4:]  # Last 4 tree7-14 address computations
+            "valu": [
+                ("vbroadcast", tree3_v, tree3_scalar),
+                ("vbroadcast", tree4_v, tree4_scalar),
+            ],
         })
-        # Bundle vbroadcasts for tree3-6
-        self.instrs.append({"valu": [
-            ("vbroadcast", tree3_v, tree3_scalar),
-            ("vbroadcast", tree4_v, tree4_scalar),
+        # Broadcast tree5,6 and compute diff_3_4 (all VALU)
+        self.add_packed({"valu": [
             ("vbroadcast", tree5_v, tree5_scalar),
             ("vbroadcast", tree6_v, tree6_scalar),
+            ("-", diff_3_4_v, tree4_v, tree3_v),
         ]})
+        # diff_5_6 will be deferred to combine with first hash const load below
+        deferred_diff_5_6 = ("-", diff_5_6_v, tree6_v, tree5_v)
 
-        # Bundle loads (2 per cycle, 4 bundles)
-        for i in range(0, 8, 2):
-            self.instrs.append({"load": [
-                ("load", tree7_14_scalars[i], tree7_14_scalars[i]),
-                ("load", tree7_14_scalars[i+1], tree7_14_scalars[i+1]),
-            ]})
-
-        # Bundle vbroadcasts (6 per cycle, plus seven_v)
-        self.instrs.append({"valu": [
-            ("vbroadcast", seven_v, seven_const),
-            ("vbroadcast", tree7_14_v[0], tree7_14_scalars[0]),
-            ("vbroadcast", tree7_14_v[1], tree7_14_scalars[1]),
-            ("vbroadcast", tree7_14_v[2], tree7_14_scalars[2]),
-            ("vbroadcast", tree7_14_v[3], tree7_14_scalars[3]),
-            ("vbroadcast", tree7_14_v[4], tree7_14_scalars[4]),
-        ]})
-        self.instrs.append({"valu": [
-            ("vbroadcast", tree7_14_v[5], tree7_14_scalars[5]),
-            ("vbroadcast", tree7_14_v[6], tree7_14_scalars[6]),
-            ("vbroadcast", tree7_14_v[7], tree7_14_scalars[7]),
-        ]})
-
-        # Precompute diffs for rounds 2 and 3 (bundle 6 ops - tree3-6 diffs + tree7-14 diffs)
-        diff_7_8_v = self.alloc_scratch("diff_7_8_v", VLEN)
-        diff_9_10_v = self.alloc_scratch("diff_9_10_v", VLEN)
-        diff_11_12_v = self.alloc_scratch("diff_11_12_v", VLEN)
-        diff_13_14_v = self.alloc_scratch("diff_13_14_v", VLEN)
-        self.instrs.append({"valu": [
-            ("-", diff_3_4_v, tree4_v, tree3_v),                # tree4 - tree3 (for round 2)
-            ("-", diff_5_6_v, tree6_v, tree5_v),                # tree6 - tree5 (for round 2)
-            ("-", diff_7_8_v, tree7_14_v[1], tree7_14_v[0]),    # tree8 - tree7
-            ("-", diff_9_10_v, tree7_14_v[3], tree7_14_v[2]),   # tree10 - tree9
-            ("-", diff_11_12_v, tree7_14_v[5], tree7_14_v[4]),  # tree12 - tree11
-            ("-", diff_13_14_v, tree7_14_v[7], tree7_14_v[6]),  # tree14 - tree13
-        ]})
-
+        # OPTIMIZED: Load all hash constants first, then pack vbroadcasts
         hash_c1_v = []
         hash_c3_v = []
+        hash_c3_s = []
         hash_mul_v = []
-        hash_vbroadcasts = []
 
+        # Phase 1: Allocate and load all scalar constants (pack const loads 2 per cycle)
+        c1_scalars = []
+        c3_scalars = []
+        mul_scalars = []
+
+        # Collect all const values and addresses first
+        const_loads = []  # List of (addr, value)
         for hi, (op1, val1, op2, op3, val3) in enumerate(HASH_STAGES):
-            c1_scalar = self.scratch_const(val1)
+            # c1 const
+            if val1 not in self.const_map:
+                addr = self.alloc_scratch(f"hash_c1_s_{hi}")
+                self.const_map[val1] = addr
+                const_loads.append((addr, val1))
+            c1_scalars.append(self.const_map[val1])
+
+            # c3 const
+            if val3 not in self.const_map:
+                addr = self.alloc_scratch(f"hash_c3_s_{hi}")
+                self.const_map[val3] = addr
+                const_loads.append((addr, val3))
+            c3_scalars.append(self.const_map[val3])
+            hash_c3_s.append(self.const_map[val3])
+
+            # mul const for fusible stages
+            if op1 == "+" and op2 == "+" and op3 == "<<":
+                mul = (1 + (1 << val3)) % (2**32)
+                if mul not in self.const_map:
+                    addr = self.alloc_scratch(f"hash_mul_s_{hi}")
+                    self.const_map[mul] = addr
+                    const_loads.append((addr, mul))
+                mul_scalars.append((hi, self.const_map[mul]))
+            else:
+                mul_scalars.append((hi, None))
+
+        # Pack const loads 2 per cycle, combine first batch with deferred diff_5_6
+        for i in range(0, len(const_loads), 2):
+            if i + 1 < len(const_loads):
+                bundle = {"load": [
+                    ("const", const_loads[i][0], const_loads[i][1]),
+                    ("const", const_loads[i + 1][0], const_loads[i + 1][1]),
+                ]}
+                # Combine diff_5_6 with first batch of const loads (saves 1 cycle)
+                if i == 0 and deferred_diff_5_6:
+                    bundle["valu"] = [deferred_diff_5_6]
+                self.add_packed(bundle)
+            else:
+                self.add("load", ("const", const_loads[i][0], const_loads[i][1]))
+
+        # Phase 2: Allocate vector destinations
+        for hi in range(len(HASH_STAGES)):
             c1_v = self.alloc_scratch(f"hash_c1_v_{hi}", VLEN)
-            hash_vbroadcasts.append(("vbroadcast", c1_v, c1_scalar))
-            c3_scalar = self.scratch_const(val3)
             c3_v = self.alloc_scratch(f"hash_c3_v_{hi}", VLEN)
-            hash_vbroadcasts.append(("vbroadcast", c3_v, c3_scalar))
             hash_c1_v.append(c1_v)
             hash_c3_v.append(c3_v)
-            mul_v = None
-            if op1 == "+" and op2 == "+" and op3 == "<<":
-                mul = (1 + (1 << val3)) % (2**32)
-                mul_scalar = self.scratch_const(mul)
+
+        for hi, mul_scalar in mul_scalars:
+            if mul_scalar is not None:
                 mul_v = self.alloc_scratch(f"hash_mul_v_{hi}", VLEN)
-                hash_vbroadcasts.append(("vbroadcast", mul_v, mul_scalar))
-            hash_mul_v.append(mul_v)
+                hash_mul_v.append(mul_v)
+            else:
+                hash_mul_v.append(None)
 
-        # Bundle hash vbroadcasts (6 per cycle)
-        for i in range(0, len(hash_vbroadcasts), 6):
-            chunk = hash_vbroadcasts[i:i+6]
-            self.instrs.append({"valu": chunk})
+        # Setup for block offset loading
+        vector_batch_temp = (batch_size // VLEN) * VLEN
+        block_offset_values = list(range(0, vector_batch_temp, VLEN))  # 0, 8, 16, ..., 248
 
-        # Pre-allocate everything before pause (so const loads go to init)
-        vector_batch = (batch_size // VLEN) * VLEN
-        vector_blocks = vector_batch // VLEN
-        pipe_buffers = min(10, vector_blocks) if vector_blocks else 0
+        # Allocate all block offset addresses upfront
+        block_off_addrs = []
+        for i in range(len(block_offset_values)):
+            addr = self.alloc_scratch(f"block_off_{i}")
+            self.const_map[block_offset_values[i]] = addr
+            block_off_addrs.append(addr)
+
+        # Load only base offsets (every 4th); compute the rest with ALU adds.
+        base_indices = list(range(0, len(block_offset_values), 4))
+        block_offset_loads = [
+            (block_off_addrs[i], block_offset_values[i]) for i in base_indices
+        ]
+        eight_const = self.alloc_scratch("eight_const")
+        sixteen_const = self.alloc_scratch("sixteen_const")
+        twentyfour_const = self.alloc_scratch("twentyfour_const")
+        self.const_map[8] = eight_const
+        self.const_map[16] = sixteen_const
+        self.const_map[24] = twentyfour_const
+        block_offset_loads.append((eight_const, 8))
+        block_offset_loads.append((sixteen_const, 16))
+        block_offset_loads.append((twentyfour_const, 24))
+
+        # Phase 3: Interleave vbroadcasts with block offset loads
+        # We have 12 vbroadcasts (6 c1 + 6 c3) and 3 mul broadcasts = 15 valu ops
+        # Plus 11 block offset const loads (base offsets + 8/16/24 constants)
+
+        # Strategy: pair const loads with vbroadcasts (2 loads + up to 6 valu per cycle)
+        all_broadcasts = []
+        for i in range(len(HASH_STAGES)):
+            all_broadcasts.append(("vbroadcast", hash_c1_v[i], c1_scalars[i]))
+        for i in range(len(HASH_STAGES)):
+            all_broadcasts.append(("vbroadcast", hash_c3_v[i], c3_scalars[i]))
+        for hi in range(len(HASH_STAGES)):
+            if hash_mul_v[hi] is not None:
+                all_broadcasts.append(("vbroadcast", hash_mul_v[hi], mul_scalars[hi][1]))
+
+        # Pack: 2 const loads + 6 vbroadcasts per cycle while we have both
+        bc_idx = 0
+        const_idx = 0
+        while bc_idx < len(all_broadcasts) or const_idx < len(block_offset_loads):
+            bundle = {}
+
+            # Add up to 6 vbroadcasts
+            valu_ops = []
+            while len(valu_ops) < 6 and bc_idx < len(all_broadcasts):
+                valu_ops.append(all_broadcasts[bc_idx])
+                bc_idx += 1
+            if valu_ops:
+                bundle["valu"] = valu_ops
+
+            # Add up to 2 const loads
+            load_ops = []
+            while len(load_ops) < 2 and const_idx < len(block_offset_loads):
+                addr, val = block_offset_loads[const_idx]
+                load_ops.append(("const", addr, val))
+                const_idx += 1
+            if load_ops:
+                bundle["load"] = load_ops
+
+            if bundle:
+                self.add_packed(bundle)
+
+        # Compute remaining block offsets using ALU adds from the base offsets.
+        offset_alu_ops = []
+        for base_idx in base_indices:
+            base_addr = block_off_addrs[base_idx]
+            offset_alu_ops.append(("+", block_off_addrs[base_idx + 1], base_addr, eight_const))
+            offset_alu_ops.append(("+", block_off_addrs[base_idx + 2], base_addr, sixteen_const))
+            offset_alu_ops.append(("+", block_off_addrs[base_idx + 3], base_addr, twentyfour_const))
+            if len(offset_alu_ops) == SLOT_LIMITS["alu"]:
+                self.add_packed({"alu": offset_alu_ops})
+                offset_alu_ops = []
+        if offset_alu_ops:
+            self.add_packed({"alu": offset_alu_ops})
+
+        # Add pause after all init
+        self.add_packed({"flow": [("pause",)]})
+        body_instrs = []
 
         buffers = []
+        vector_batch = (batch_size // VLEN) * VLEN
+        vector_blocks = vector_batch // VLEN
+        pipe_buffers = min(13, vector_blocks) if vector_blocks else 0  # optimized from 10
         for bi in range(pipe_buffers):
             buffers.append({
                 "idx": self.alloc_scratch(f"idx_v{bi}", VLEN),
@@ -324,14 +392,9 @@
         tmp_node_val = self.alloc_scratch("tmp_node_val")
         tmp_addr = self.alloc_scratch("tmp_addr")
 
-        # Pre-create all block offsets in batch (bundled const loads)
-        block_offset_values = list(range(0, vector_batch, VLEN))
-        block_offsets = self.scratch_consts_batch(block_offset_values)
+        # Block offsets already loaded above
+        block_offsets = block_off_addrs
 
-        self.add("flow", ("pause",))
-        self.add("debug", ("comment", "Starting loop"))
-        body_instrs = []
-
         def schedule_all_rounds():
             if vector_blocks == 0:
                 return []
@@ -379,24 +442,42 @@
 
                 scheduled_this_cycle = set()
 
-                # Wrap threshold: only need bounds check when max idx can exceed n_nodes
+                # Wrap threshold: only need bounds check after round 9 for n_nodes=2047
                 # Max idx after round r is 2^(r+2) - 2
-                # wrap_threshold = smallest r where 2^(r+2) >= n_nodes + 2
-                wrap_threshold = (n_nodes + 1).bit_length() - 2
+                # After round 9: 2046 < 2047 (no wrap), after round 10: 4094 > 2047 (wrap)
+                wrap_threshold = 10
 
                 def next_round_phase(current_round):
                     """Determine next phase after completing a round."""
                     next_r = current_round + 1
                     if next_r >= rounds:
                         return "store_both"
-                    elif next_r == 1:
+
+                    # Calculate effective depth
+                    # For rounds 0-wrap_threshold, depth = next_r
+                    # For rounds after wrap (11+), depth restarts from 0
+                    # After wrap at round 10, indices reset to 0, so:
+                    #   round 11 = depth 0, round 12 = depth 1, etc.
+                    if next_r <= wrap_threshold:
+                        depth = next_r
+                    else:
+                        # After wrap: round 11 = depth 0, round 12 = depth 1, etc.
+                        depth = next_r - wrap_threshold - 1
+
+                    # Use selection for depths 0-2 (both before and after wrap).
+                    # Depth 3+ selection adds too much VALU - use gather instead.
+                    is_after_wrap = next_r > wrap_threshold
+
+                    if depth == 0:
+                        # Round 0 never hits this (special-cased in vload)
+                        # But round 11 (after wrap) does
+                        return "round0_xor"
+                    elif depth == 1:
                         return "round1_select"
-                    elif next_r == 2:
+                    elif depth == 2:
                         return "round2_select1"
-                    elif next_r == 3:
-                        return "round3_select1"
                     else:
-                        return "addr"
+                        return "addr"  # Gather for depth >= 3
 
                 # Priority 1: Flow operations (vselect for bounds) - only for rounds >= wrap_threshold
                 update4_blocks = [b for b in active if b["phase"] == "update4" and b["block"] not in scheduled_this_cycle]
@@ -489,69 +570,76 @@
                     elif phase == "update1":
                         valu_tasks.append((2, 2, block, "update1"))
                     elif phase == "hash_op2":
-                        valu_tasks.append((6, 1, block, "hash_op2"))
+                        valu_tasks.append((5, 1, block, "hash_op2"))
                     elif phase == "hash_mul":
-                        valu_tasks.append((6, 1, block, "hash_mul"))
+                        valu_tasks.append((3, 1, block, "hash_mul"))
                     elif phase == "hash_op1":
-                        valu_tasks.append((5, 2, block, "hash_op1"))
+                        valu_tasks.append((5, 1, block, "hash_op1"))
                     elif phase == "xor":
                         valu_tasks.append((7, 1, block, "xor"))
                     elif phase == "round0_xor":
                         valu_tasks.append((7, 1, block, "round0_xor"))
                     elif phase == "round1_select":
-                        valu_tasks.append((6, 2, block, "round1_select"))  # combined: offset + node
+                        valu_tasks.append((7, 1, block, "round1_select"))  # optimized from 6 to 7
                     elif phase == "round2_select1":
-                        valu_tasks.append((6, 1, block, "round2_select1"))  # offset
+                        valu_tasks.append((6, 1, block, "round2_select1"))  # offset, priority 6
                     elif phase == "round2_select2":
-                        valu_tasks.append((6, 2, block, "round2_select2"))  # sel0, sel1
+                        valu_tasks.append((4, 1, block, "round2_select2"))  # sel1, priority 4 (optimized)
                     elif phase == "round2_select3":
-                        valu_tasks.append((6, 2, block, "round2_select3"))  # low, high
+                        valu_tasks.append((6, 2, block, "round2_select3"))  # low, high, priority 6
                     elif phase == "round2_select4":
                         valu_tasks.append((6, 1, block, "round2_select4"))  # diff
                     elif phase == "round2_select5":
                         valu_tasks.append((6, 1, block, "round2_select5"))  # node
-                    elif phase == "round3_select1":
-                        valu_tasks.append((6, 1, block, "round3_select1"))  # offset = idx - 7
-                    elif phase == "round3_select2":
-                        valu_tasks.append((6, 3, block, "round3_select2"))  # sel0, sel1, sel2
-                    elif phase == "round3_select3":
-                        valu_tasks.append((6, 3, block, "round3_select3"))  # sel1, t01, t23
-                    elif phase == "round3_select4a":
-                        valu_tasks.append((6, 1, block, "round3_select4a"))  # d01_23
-                    elif phase == "round3_select4b":
-                        valu_tasks.append((6, 1, block, "round3_select4b"))  # t0123
-                    elif phase == "round3_select5":
-                        valu_tasks.append((6, 2, block, "round3_select5"))  # t45, t67
-                    elif phase == "round3_select6a":
-                        valu_tasks.append((6, 1, block, "round3_select6a"))  # d45_67
-                    elif phase == "round3_select6b":
-                        valu_tasks.append((6, 1, block, "round3_select6b"))  # t4567
-                    elif phase == "round3_select7a":
-                        valu_tasks.append((6, 1, block, "round3_select7a"))  # diff
-                    elif phase == "round3_select7b":
-                        valu_tasks.append((6, 1, block, "round3_select7b"))  # node
-                    elif phase == "addr":
-                        # Higher priority (3) to feed gather pipeline
-                        valu_tasks.append((3, 1, block, "addr"))
+                    elif phase == "addr":
+                        # Optimized priority (5) for better scheduling
+                        valu_tasks.append((5, 1, block, "addr"))
 
                 # Sort by priority (lower = higher priority)
                 valu_tasks.sort(key=lambda x: x[0])
 
                 # Schedule tasks greedily
                 for priority, cost, block, phase in valu_tasks:
-                    if valu_slots < cost:
-                        continue
                     if block["block"] in scheduled_this_cycle:
                         continue
                     buf = block["buf"]
 
+                    if phase == "hash_op1":
+                        hi = block["stage"]
+                        op1 = HASH_STAGES[hi][0]
+                        op3 = HASH_STAGES[hi][3]
+                        # Prefer offloading op3 shift to scalar ALU (8 lanes) when slots allow.
+                        if alu_slots >= VLEN and valu_slots >= 1:
+                            valu_ops.append((op1, buf["tmp1"], buf["val"], hash_c1_v[hi]))
+                            for lane in range(VLEN):
+                                alu_ops.append((op3, buf["tmp2"] + lane, buf["val"] + lane, hash_c3_s[hi]))
+                            alu_slots -= VLEN
+                            valu_slots -= 1
+                            block["next_phase"] = "hash_op2"
+                            scheduled_this_cycle.add(block["block"])
+                            continue
+                        if valu_slots >= 2:
+                            valu_ops.append((op1, buf["tmp1"], buf["val"], hash_c1_v[hi]))
+                            valu_ops.append((op3, buf["tmp2"], buf["val"], hash_c3_v[hi]))
+                            valu_slots -= 2
+                            block["next_phase"] = "hash_op2"
+                            scheduled_this_cycle.add(block["block"])
+                            continue
+                        continue
+
+                    if valu_slots < cost:
+                        continue
+
                     if phase == "update3":
                         valu_ops.append(("<", buf["cond"], buf["idx"], n_nodes_v))
                         block["next_phase"] = "update4"
                     elif phase == "update2":
                         valu_ops.append(("+", buf["idx"], buf["idx"], buf["tmp1"]))
-                        # Skip wrap check for early rounds (idx can't exceed n_nodes)
-                        if block["round"] < wrap_threshold:
+                        # Skip wrap check for rounds where idx can't exceed n_nodes:
+                        # - Rounds 0-9 (before wrap): idx grows but stays < n_nodes
+                        # - Rounds 11-15 (after wrap): idx reset to 0 and grows small
+                        # Only round 10 (wrap_threshold) needs the wrap check
+                        if block["round"] != wrap_threshold:
                             block["round"] += 1
                             block["stage"] = 0
                             block["gather"] = 0
@@ -580,13 +668,6 @@
                         else:
                             block["stage"] = hi + 1
                             block["next_phase"] = "hash_mul" if hash_mul_v[hi + 1] is not None else "hash_op1"
-                    elif phase == "hash_op1":
-                        hi = block["stage"]
-                        op1 = HASH_STAGES[hi][0]
-                        op3 = HASH_STAGES[hi][3]
-                        valu_ops.append((op1, buf["tmp1"], buf["val"], hash_c1_v[hi]))
-                        valu_ops.append((op3, buf["tmp2"], buf["val"], hash_c3_v[hi]))
-                        block["next_phase"] = "hash_op2"
                     elif phase == "xor":
                         valu_ops.append(("^", buf["val"], buf["val"], buf["node"]))
                         block["next_phase"] = "hash_mul" if hash_mul_v[0] is not None else "hash_op1"
@@ -595,78 +676,35 @@
                         valu_ops.append(("^", buf["val"], buf["val"], tree0_v))
                         block["next_phase"] = "hash_mul" if hash_mul_v[0] is not None else "hash_op1"
                     elif phase == "round1_select":
-                        # Round 1: idx in {1,2}, use linear interpolation
-                        # offset = idx - 1, node = tree1 + offset * (tree2 - tree1)
-                        valu_ops.append(("-", buf["tmp1"], buf["idx"], one_v))
+                        # Round 1: idx in {1,2}. tmp1 already holds parity == idx - 1.
+                        # node = tree1 + tmp1 * (tree2 - tree1)
                         valu_ops.append(("multiply_add", buf["node"], diff_1_2_v, buf["tmp1"], tree1_v))
                         block["next_phase"] = "xor"
                     elif phase == "round2_select1":
-                        # Round 2: compute offset = idx - 3
-                        valu_ops.append(("-", buf["tmp1"], buf["idx"], three_v))
+                        # Round 2: compute offset = idx - 3 into tmp2 (preserve tmp1 parity)
+                        # Then compute sel1 = offset >> 1 in next cycle
+                        valu_ops.append(("-", buf["tmp2"], buf["idx"], three_v))
                         block["next_phase"] = "round2_select2"
                     elif phase == "round2_select2":
-                        # Compute sel0 = offset & 1, sel1 = offset >> 1
-                        valu_ops.append(("&", buf["tmp2"], buf["tmp1"], one_v))   # sel0
-                        valu_ops.append((">>", buf["cond"], buf["tmp1"], one_v))  # sel1
+                        # Compute sel1 = offset >> 1
+                        # Try to also do low/high computations if we have slots (they don't depend on cond yet)
+                        valu_ops.append((">>", buf["cond"], buf["tmp2"], one_v))  # sel1
                         block["next_phase"] = "round2_select3"
                     elif phase == "round2_select3":
-                        # Compute low and high using linear interpolation
-                        valu_ops.append(("multiply_add", buf["tmp1"], diff_3_4_v, buf["tmp2"], tree3_v))  # low
-                        valu_ops.append(("multiply_add", buf["node"], diff_5_6_v, buf["tmp2"], tree5_v))  # high
+                        # Compute low/high; sel0 == parity in tmp1
+                        valu_ops.append(("multiply_add", buf["tmp2"], diff_3_4_v, buf["tmp1"], tree3_v))  # low
+                        valu_ops.append(("multiply_add", buf["node"], diff_5_6_v, buf["tmp1"], tree5_v))  # high
                         block["next_phase"] = "round2_select4"
                     elif phase == "round2_select4":
-                        # Compute diff = high - low
-                        valu_ops.append(("-", buf["tmp2"], buf["node"], buf["tmp1"]))
+                        # Compute diff = high - low, then final selection if we have 2 slots
+                        # node = node - tmp2, then node = node * cond + tmp2
+                        # These have RAW dependency (second reads node from first), so can't combine
+                        valu_ops.append(("-", buf["node"], buf["node"], buf["tmp2"]))
                         block["next_phase"] = "round2_select5"
                     elif phase == "round2_select5":
                         # Final selection: node = low + sel1 * diff
-                        valu_ops.append(("multiply_add", buf["node"], buf["tmp2"], buf["cond"], buf["tmp1"]))
+                        valu_ops.append(("multiply_add", buf["node"], buf["node"], buf["cond"], buf["tmp2"]))
                         block["next_phase"] = "xor"
-                    elif phase == "round3_select1":
-                        # Round 3: idx in {7..14}, compute offset = idx - 7
-                        valu_ops.append(("-", buf["tmp1"], buf["idx"], seven_v))
-                        block["next_phase"] = "round3_select2"
-                    elif phase == "round3_select2":
-                        # Compute sel0, sel1*2, sel2
-                        valu_ops.append(("&", buf["tmp2"], buf["tmp1"], one_v))   # sel0 = offset & 1
-                        valu_ops.append(("&", buf["cond"], buf["tmp1"], two_v))   # sel1*2 = offset & 2
-                        valu_ops.append((">>", buf["addr"], buf["tmp1"], two_v))  # sel2 = offset >> 2
-                        block["next_phase"] = "round3_select3"
-                    elif phase == "round3_select3":
-                        # Compute sel1, t01, t23
-                        valu_ops.append((">>", buf["cond"], buf["cond"], one_v))  # sel1 = sel1*2 >> 1
-                        valu_ops.append(("multiply_add", buf["tmp1"], diff_7_8_v, buf["tmp2"], tree7_14_v[0]))   # t01
-                        valu_ops.append(("multiply_add", buf["node"], diff_9_10_v, buf["tmp2"], tree7_14_v[2]))  # t23
-                        block["next_phase"] = "round3_select4a"
-                    elif phase == "round3_select4a":
-                        # d01_23 = t23 - t01
-                        valu_ops.append(("-", buf["node"], buf["node"], buf["tmp1"]))
-                        block["next_phase"] = "round3_select4b"
-                    elif phase == "round3_select4b":
-                        # t0123 = d01_23 * sel1 + t01
-                        valu_ops.append(("multiply_add", buf["tmp1"], buf["node"], buf["cond"], buf["tmp1"]))
-                        block["next_phase"] = "round3_select5"
-                    elif phase == "round3_select5":
-                        # Compute t45, t67
-                        valu_ops.append(("multiply_add", buf["node"], diff_11_12_v, buf["tmp2"], tree7_14_v[4]))  # t45
-                        valu_ops.append(("multiply_add", buf["tmp2"], diff_13_14_v, buf["tmp2"], tree7_14_v[6]))  # t67
-                        block["next_phase"] = "round3_select6a"
-                    elif phase == "round3_select6a":
-                        # d45_67 = t67 - t45
-                        valu_ops.append(("-", buf["tmp2"], buf["tmp2"], buf["node"]))
-                        block["next_phase"] = "round3_select6b"
-                    elif phase == "round3_select6b":
-                        # t4567 = t45 + sel1 * d45_67
-                        valu_ops.append(("multiply_add", buf["node"], buf["tmp2"], buf["cond"], buf["node"]))
-                        block["next_phase"] = "round3_select7a"
-                    elif phase == "round3_select7a":
-                        # diff = t4567 - t0123
-                        valu_ops.append(("-", buf["tmp2"], buf["node"], buf["tmp1"]))
-                        block["next_phase"] = "round3_select7b"
-                    elif phase == "round3_select7b":
-                        # node = t0123 + sel2 * diff
-                        valu_ops.append(("multiply_add", buf["node"], buf["tmp2"], buf["addr"], buf["tmp1"]))
-                        block["next_phase"] = "xor"
                     elif phase == "addr":
                         valu_ops.append(("+", buf["addr"], buf["idx"], forest_base_v))
                         block["next_phase"] = "gather"
